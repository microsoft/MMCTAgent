<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="styles/styles-imageAgent.css" />
    <title>imageAgent</title>
</head>
<body>
    <div class="main-container">
        <h1>MMCT - Image Pipeline</h1>

        <div class="small-intro"> 
            Performs image classification, Detects and localizes specific objects, Extracts text embedded within the image, Uses GPT-4V’s Vision Transformer-based reasoning to analyze the entire image holistically.​
        </div>

        <p class="author-block">
            <img src="https://upload.wikimedia.org/wikipedia/commons/4/44/Microsoft_logo.svg" alt="Microsoft Logo" class="author-logo">
            Microsoft Research
        </p>

        <div class="addImage">
            <img src="Images&icons/imageAgent.png" alt="imageAgent">
        </div>

        <div class="overview">
            <h2 class="underlined">Overview</h2>
            <p>
                <strong>Image Pipeline</strong> consists of an <strong>Image Agent</strong> which is built on top of the 
                <a href="https://arxiv.org/abs/2405.18358" target="_blank">Multi-Modal Critical Thinking (MMCT)</a> 
                architecture. It leverages two collaborative agents:
            </p>
            <ul>
                <li><strong>Planner:</strong> Generates an initial response based on the provided input. It uses a set of default tools from <code>ImageQnaTools</code> but can be customized.</li>
                <li><strong>Critic (optional):</strong> Evaluates the planner’s response and provides feedback for improvement. This feedback loop helps increase accuracy and quality.</li>
            </ul>
            <p>
                By default, the critic agent is enabled. Users can disable it by setting <code>use_critic_agent=False</code> during initialization.
            </p>
            <p class="note">
                <strong>Note:</strong> Disabling the critic agent skips the feedback loop and may reduce the accuracy of the final response.
            </p>
        </div>

        <div class="tool-config-section">
            <h2 class="underlined">Tool Configuration</h2>
            <p>
                The planner supports the following tools via the <code>ImageQnaTools</code> enum:
            </p>
            <ul>
                <li><strong>ImageQnaTools.object_detection:</strong> This tool detects the object in the image.</li>
                <li><strong>ImageQnaTools.ocr:</strong> For extracting text content.</li>
                <li><strong>ImageQnaTools.recog:</strong> This tool recognises the objects in the image.</li>
                <li><strong>ImageQnaTools.vit:</strong> For high-level visual understanding using vision transformers (e.g., GPT-4V).</li>
            </ul>
            <p>
                Users can pass a list of tools via the <code>tools</code> parameter to override the defaults.
            </p>
        </div>

        <div class="tool-config-section workflow">
            <h2 class="underlined">Tool Workflow</h2>

            <h3>1. Input Processing</h3>
            <ul>
                <li>The user provides an image input along with a query.</li>
                <li>The system is initialized with a set of tools (default or user-defined) and an optional critic agent.</li>
            </ul>

            <h3>2. Planner Agent Execution</h3>
            <ul>
                <li>The <strong>Planner</strong> is the core agent that first analyzes the input.</li>
                <li>It selects appropriate tools from <code>ImageQnaTools</code> based on the task:
                <ul>
                    <li><code>object_detection</code>: Detects objects in the image.</li>
                    <li><code>ocr</code>: Extracts textual information.</li>
                    <li><code>recog</code>: Recognizes objects/entities.</li>
                    <li><code>vit</code>: Performs high-level visual reasoning (e.g., GPT-4V).</li>
                </ul>
                </li>
                <li>It generates an initial response using the selected tools.</li>
            </ul>

            <h3>3. Critic Agent Feedback (Optional)</h3>
            <ul>
                <li>If <code>use_critic_agent = True</code> (default), the Critic reviews the Planner’s response.</li>
                <li>It evaluates the quality and correctness of the response.</li>
                <li>If necessary, it provides feedback to improve the output.</li>
                <li>This feedback loop may iterate for refinement.</li>
            </ul>

            <h3>4. Final Response</h3>
            <ul>
                <li>The system returns a response combining insights from the tools and (optionally) the critic's feedback.</li>
                <li>If the critic is disabled, the planner’s output is returned directly, which may be less refined.</li>
            </ul>

            <div class="note">
                <strong>Note:</strong> Disabling the critic agent can speed up processing but may reduce the accuracy and depth of the final result.
            </div>
        </div>

        <div class="usage">
            <div class="heading-toggle"> 
                <h2 >Usage</h2>
                <button class="toggle-btn" onclick="toggleSection('toggle-code-block', this)">
                    <img src="https://cdn-icons-png.flaticon.com/512/130/130907.png" alt="Toggle" />
                </button>
            </div>
             
            <div id = 'toggle-code-block' style="display: none;">
                <p>Below is the script to get started with the <strong>MMCT Image Agent</strong>.</p>

            <pre class="code-block" >
            <code>
    from mmct.image_pipeline import ImageAgent, ImageQnaTools
    import asyncio
    import ast

    # user query
    query = ""

    # define the tools, you can refer to the Enum definition of Tools to get the idea for 
    available tools
    tools = [ImageQnaTools.object_detection, ImageQnaTools.vit]

    # flag variable whether you want to initialize Critic Agent or not
    use_critic_agent = True

    # flag variable whether you have to stream or not
    stream = False

    # initialize the Image Agent
    mmct_agent = ImageAgent(
        query=query,
        image_path=image_path,
        tools=tools,
        use_critic_agent=use_critic_agent,
        stream=stream,
    )

    response = asyncio.run(mmct_agent.run())
    response = ast.literal_eval(response.content.split("TERMINATE")[0])
    print(response)
            </code></pre>
            </div>    

        </div>

            <div class="qna">
                <h2 class="underlined">QnA</h2>
            </div>

            <!-- License -->
            <div class="license">
                <h2 class="underlined">License</h2>
                <div class="section-box">
                    <p>Microsoft's autogen</p>
                </div>
            </div>

    </div>

    <script>
        function toggleSection(sectionId, btn) {
            const section = document.getElementById(sectionId);
            const img = btn.querySelector("img");

            if (section.style.display === "none" || section.style.display === "") {
                section.style.display = "block";
                img.src = "https://cdn-icons-png.flaticon.com/512/130/130906.png"; // up arrow
            } else {
                section.style.display = "none";
                img.src = "https://cdn-icons-png.flaticon.com/512/130/130907.png"; // down arrow
            }
        }
    </script>

</body>
</html>